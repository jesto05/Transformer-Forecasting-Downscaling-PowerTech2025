{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0692fec4-2c43-4e81-9c0c-2f083d6e087b",
   "metadata": {},
   "source": [
    "# Solar_Irradiance_Prediction_using_Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21558dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import (mean_squared_error,\n",
    "                             mean_absolute_error)\n",
    "import time\n",
    "import re\n",
    "import os   \n",
    "import torch, math\n",
    "import numpy as np\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.transformer import TransformerEncoderLayer\n",
    "import pickle\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea364e-db91-4970-973a-8703f51c4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date and time(for saving file)\n",
    "new_file_number=\"DEMO\"\n",
    "formatted_datetime = \"XX_XX_XXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca17e10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_global=pd.read_csv(\"global.csv\")\n",
    "df_local=pd.read_csv(\"local.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ec0077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure and two subplots (1 column, 2 rows)\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 8))  # 2 rows, 1 column\n",
    "\n",
    "# Plot the first subplot\n",
    "axs[0].plot(df_global[\"shortwave_radiation_instant (W/m²)\"], color='blue')\n",
    "axs[0].set_title('Global Irradiance')\n",
    "axs[0].set_ylabel('Irradiance')\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot the second subplot\n",
    "axs[1].plot(df_local[\"Solar Radiation (W/m^2)\"], color='green')\n",
    "axs[1].set_title('Local Irradiance')\n",
    "axs[1].set_ylabel('Irradiance')\n",
    "axs[1].set_xlabel('Time(15 MIN)')\n",
    "axs[1].grid()\n",
    "\n",
    "# # Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733955b-dd89-4c7d-aa7c-d705bf45b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gettign Index Number to Save File in Numerical Order\n",
    "results_dir = \"Results_Table\"\n",
    "saved_models_dir=\"saved_models\"\n",
    "\n",
    "existing_files = os.listdir(results_dir)\n",
    "pattern = r\"^(\\d+)_Results\"\n",
    "existing_numbers = []\n",
    "\n",
    "for filename in existing_files:\n",
    "    match = re.match(pattern, filename)\n",
    "    if match:\n",
    "        existing_numbers.append(int(match.group(1)))\n",
    "\n",
    "# If no existing files, start from 1\n",
    "if existing_numbers:\n",
    "    new_file_number = max(existing_numbers) + 1\n",
    "else:\n",
    "    new_file_number = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3792a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forecoasting Model\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 10000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# A forcasting model\n",
    "class ForecastingModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 seq_len,\n",
    "                 embed_size = 8, \n",
    "                 nhead = 2,\n",
    "                 dim_feedforward = 1024, \n",
    "                 dropout = 0.1,\n",
    "                 conv1d_emb = True,\n",
    "                 conv1d_kernel_size = 3,\n",
    "                 device = \"cuda\"):\n",
    "        super(ForecastingModel, self).__init__()\n",
    "\n",
    "        # Set Class-level Parameters\n",
    "        self.device = device\n",
    "        self.conv1d_emb = conv1d_emb\n",
    "        self.conv1d_kernel_size = conv1d_kernel_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # Input Embedding Component\n",
    "        if conv1d_emb:\n",
    "            if conv1d_kernel_size%2==0:\n",
    "                raise Exception(\"conv1d_kernel_size must be an odd number to preserve dimensions.\")\n",
    "            self.conv1d_padding = conv1d_kernel_size - 1\n",
    "            self.input_embedding  = nn.Conv1d(1, embed_size, kernel_size=conv1d_kernel_size)\n",
    "        else: self.input_embedding  = nn.Linear(1, embed_size)\n",
    "\n",
    "        # Positional Encoder Componet (See Code Copied from PyTorch Above)\n",
    "        self.position_encoder = PositionalEncoding(d_model=embed_size, \n",
    "                                                   dropout=dropout,\n",
    "                                                   max_len=seq_len)\n",
    "        \n",
    "        # Transformer Encoder Layer Component\n",
    "        self.transformer_encoder = TransformerEncoderLayer(\n",
    "            d_model = embed_size,\n",
    "            nhead = nhead,\n",
    "            dim_feedforward = dim_feedforward,\n",
    "            dropout = dropout,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        # Regression Component\n",
    "        self.linear1 = nn.Linear(seq_len*embed_size, int(dim_feedforward))\n",
    "        self.linear2 = nn.Linear(int(dim_feedforward), int(dim_feedforward/2))\n",
    "        self.linear3 = nn.Linear(int(dim_feedforward/2), int(dim_feedforward/4))\n",
    "        self.linear4 = nn.Linear(int(dim_feedforward/4), int(dim_feedforward/16))\n",
    "        self.linear5 = nn.Linear(int(dim_feedforward/16), int(dim_feedforward/64))\n",
    "        self.outlayer = nn.Linear(int(dim_feedforward/64), 1)\n",
    "\n",
    "        # Basic Components\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Model Forward Pass\n",
    "    def forward(self, x):\n",
    "        src_mask = self._generate_square_subsequent_mask()\n",
    "        src_mask.to(self.device)\n",
    "        if self.conv1d_emb: \n",
    "            x = F.pad(x, (0, 0, self.conv1d_padding, 0), \"constant\", -1)\n",
    "            x = self.input_embedding(x.transpose(1, 2))\n",
    "            x = x.transpose(1, 2)\n",
    "        else: \n",
    "            x = self.input_embedding(x)\n",
    "        x = self.position_encoder(x)\n",
    "        x = self.transformer_encoder(x, src_mask=src_mask).reshape((-1, self.seq_len*self.embed_size))\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear5(x)\n",
    "        x = self.relu(x)\n",
    "        return self.outlayer(x)\n",
    "    \n",
    "    # Function Copied from PyTorch Library to create upper-triangular source mask\n",
    "    def _generate_square_subsequent_mask(self):\n",
    "        return torch.triu(\n",
    "            torch.full((self.seq_len, self.seq_len), float('-inf'), dtype=torch.float32, device=self.device),\n",
    "            diagonal=1,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c93336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "\n",
    "#Number of datapoints in 24 Hours\n",
    "Hours_24=96 #96 for 15min Dataset Model (Should be 288 for 5min dataset model)\n",
    "\n",
    "data_x = list(df_global['shortwave_radiation_instant (W/m²)'])\n",
    "data_y = list(df_local[\"Solar Radiation (W/m^2)\"])\n",
    "x = np.array(data_x[:-Hours_24])  # Example size of x\n",
    "y = np.array(data_y[:-Hours_24])  # Example size of y\n",
    "forcast = np.array(data_y[-Hours_24:])  # Forecast data\n",
    "\n",
    "#Training Loop GRID\n",
    "seq_len = [24, 48, 96, 192, 240, 288, 384]\n",
    "batch = [1, 2, 3, 4, 5, 6 ,7]\n",
    "Epochs = [80, 90, 100, 200, 300, 400, 500]\n",
    "learning_rate=[0.01,0.05,0.001,0.005,0.00001,0.00005,6.6E-6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5183d5-a34a-4a31-8df3-047a64312f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories to save models and plots\n",
    "model_save_dir = \"saved_models\"\n",
    "plot_save_dir = \"saved_plots\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a10e05-e6a0-4f59-a172-22360a74040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_time = []\n",
    "results = [] \n",
    "models_csv=[]\n",
    "run_number=1\n",
    "\n",
    "#Training\n",
    "for i in range(len(seq_len)):\n",
    "    for j in range(len(batch)):  # Loop over batch sizes\n",
    "        for k in range(len(Epochs)):  # Loop over epochs\n",
    "            for m in range(len(learning_rate)):\n",
    "                # Rearranging Data Shape\n",
    "                X = np.array([x[ii:ii + seq_len[i]] for ii in range(0, x.shape[0] - seq_len[i])]).reshape((-1, seq_len[i], 1))\n",
    "                Y = np.array([y[ii + seq_len[i]] for ii in range(0, y.shape[0] - seq_len[i])]).reshape((-1, 1))\n",
    "    \n",
    "                start_time = time.time()\n",
    "                device = \"cuda:0\"\n",
    "                EPOCHS = Epochs[k]  # Select the current epoch count\n",
    "                BATCH_SIZE = batch[j]  # Select the current batch size\n",
    "                LEARNING_RATE = learning_rate[m]\n",
    "\n",
    "                model = ForecastingModel(seq_len=seq_len[i], embed_size=8, nhead=2, \n",
    "                                         dim_feedforward=1024, dropout=0.1, \n",
    "                                         conv1d_emb=True, conv1d_kernel_size=3, device=device).to(device)\n",
    "                \n",
    "                \n",
    "                model.train()\n",
    "                criterion = torch.nn.HuberLoss()\n",
    "                optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate[m])\n",
    "                scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "                dataset = TensorDataset(torch.Tensor(X).to(device), torch.Tensor(Y).to(device))\n",
    "                dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "    \n",
    "                # Create a list to store losses for this combination of seq_len and batch_size\n",
    "                current_loss_list = []\n",
    "    \n",
    "                for epoch in range(EPOCHS):\n",
    "                    for xx, yy in dataloader:\n",
    "                        optimizer.zero_grad()\n",
    "                        out = model(xx)\n",
    "                        loss = criterion(out, yy)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    current_loss_list.append(loss.item())\n",
    "                    # print(f\"Epoch {epoch + 1}/{EPOCHS}: Loss={loss}\")\n",
    "    \n",
    "                end_time = time.time()\n",
    "                \n",
    "                exec_time = end_time - start_time\n",
    "                execution_time.append(exec_time)\n",
    "                print(f\"Completed Seq Len {seq_len[i]}, Batch Size {BATCH_SIZE},Epoch Size {EPOCHS},Learning Rate {LEARNING_RATE}, in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "                # Save the model\n",
    "                model_save_dir = \"saved_models\"\n",
    "                datetime_model_save_dir = os.path.join(model_save_dir, f\"{new_file_number}_{formatted_datetime}\")\n",
    "                os.makedirs(datetime_model_save_dir, exist_ok=True)\n",
    "                model_save_path = os.path.join(datetime_model_save_dir, f\"{run_number}_model_seq_len_{seq_len[i]}_batch_{BATCH_SIZE}_epochs_{EPOCHS}_learning_rate_{LEARNING_RATE}.pth\")\n",
    "                torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "                \n",
    "                # Serialize the model's state_dict\n",
    "                state_dict_binary = pickle.dumps(model.state_dict())\n",
    "                # Encode the binary data into base64 to store in a text format\n",
    "                state_dict_base64 = base64.b64encode(state_dict_binary).decode('utf-8')\n",
    "                    \n",
    "                \n",
    "                \n",
    "                # Prediction Loop\n",
    "                model.eval()\n",
    "                x_copy=np.copy(x)\n",
    "                predictions = []\n",
    "                \n",
    "                for ff in range(len(forcast)):\n",
    "                    xxx = x_copy[-seq_len[i]:]\n",
    "                    yyy = model(torch.Tensor(xxx).reshape((1, seq_len[i], 1)).to(device))\n",
    "                    x_copy= np.concatenate((x_copy, yyy.detach().cpu().numpy().reshape(1,)))\n",
    "                    predictions.append(yyy.detach().cpu().numpy().flatten())\n",
    "    \n",
    "\n",
    "                predictions = np.array(predictions).flatten()\n",
    "                rmse = np.sqrt(np.mean((predictions - forcast)**2))\n",
    "                print(f\"Completed Seq Len {seq_len[i]}, Batch Size {BATCH_SIZE},Epoch Size {EPOCHS},Learning Rate {LEARNING_RATE}, in {end_time - start_time:.2f} seconds, RMSE: {rmse}\")\n",
    "\n",
    "                run_number=run_number+1\n",
    "\n",
    "                 # Append results to the results list\n",
    "                results.append({\n",
    "                    'seq_len': seq_len[i],\n",
    "                    'batch_size': BATCH_SIZE,\n",
    "                    'epochs': EPOCHS,\n",
    "                    'learning_rate':LEARNING_RATE,\n",
    "                    'execution_time': exec_time,\n",
    "                    'RMSE':rmse,\n",
    "                    'Predictions': str([float(value) for value in predictions]), \n",
    "                    'Loss':current_loss_list})\n",
    "\n",
    "                models_csv.append({\n",
    "                    'seq_len': seq_len[i],\n",
    "                    'batch_size': BATCH_SIZE,\n",
    "                    'epochs': EPOCHS,\n",
    "                    'learning_rate':LEARNING_RATE,\n",
    "                    'execution_time': exec_time,\n",
    "                    'RMSE':rmse,\n",
    "                    'Predictions':  str([float(value) for value in predictions]),\n",
    "                    'Loss':current_loss_list,\n",
    "                    'model_parameters': state_dict_base64,\n",
    "                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0ef40-b07c-41b0-bcdd-8cf97f54e02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Final Results\n",
    "results_df = pd.DataFrame(results)\n",
    "models_csv_df=pd.DataFrame(models_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e6c90e-50bb-428a-b97d-83ffffe27712",
   "metadata": {},
   "source": [
    "### AFTER TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856adc1b-63c7-4407-b109-9b1a181331df",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Predictions'] = results_df['Predictions'].apply(lambda x: list(map(float, x.strip('[]').split())))\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4ebd7-46df-4729-927e-8cb2430e5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINDING THE LOWEST RMSE\n",
    "min_rmse_row = results_df.nsmallest(1, 'RMSE')\n",
    "min_rmse_row\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch2.2]",
   "language": "python",
   "name": "conda-env-torch2.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
